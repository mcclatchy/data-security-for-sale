{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8c85a11",
   "metadata": {},
   "source": [
    "# (A) Statewide Hexmap: Reading Data and Outputting Hex-Binned Files\n",
    "\n",
    "A select list of cleaned and processed data used to power the SFR (Single Family Residential) investor project.\n",
    "\n",
    "***NOTE: The data here is PRELIMINARY and are subject to change as additional verification, fact-checking, etc. takes place. If you spot any errors, please contact [Tyler Dukes](mtdukes@newsobserver.com).***\n",
    "\n",
    "- **investors_labeled** A comma-separated value file of investor LLCs, DBAs and other entities and their variations linked to parent companies, based on a variety of sources. Filename includes datetime the list was last generated.\n",
    "- **wake_sfr_investors** Comma-separated value file of Wake County properties joined with and filtered for all owners identified as investors. NOTE: list includes iBuyers. *Filename includes date the list was last generated.*\n",
    "- **mecklenburg_sfr_investors** Comma-separated value file of Mecklenburg County properties joined with and filtered for all owners identified as investors. Filename includes datetime the list was last generated. *NOTE: List includes iBuyers.*\n",
    "- **onemap_investors** Comma-separated value file of Mecklenburg County properties joined with and filtered for all owners identified as investors. Filename includes datetime the list was last generated. *NOTE: list includes iBuyers and may include properties that are not single-family homes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6571a242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import overpass\n",
    "import geojson\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "# To run these steps you need a local version of Mapshaper (mapshaper.org)\n",
    "MAPSHAPER = os.path.join(os.path.expanduser('~'), \"node_modules/mapshaper/bin/mapshaper\")\n",
    "DATA_DIRECTORY = os.path.join(os.getcwd(), 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7455889",
   "metadata": {},
   "source": [
    "### (1) Reading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "022b9665",
   "metadata": {},
   "outputs": [],
   "source": [
    "investors_labeled = pd.read_csv(os.path.join(\n",
    "    DATA_DIRECTORY, \"investors_labeled202204120828.txt\"\n",
    "))\n",
    "mecklenburg_sfr_investors = pd.read_csv(os.path.join(\n",
    "    DATA_DIRECTORY, \"mecklenburg_sfr_investors202203211519.txt\"\n",
    "))\n",
    "wake_sfr_investors = pd.read_csv(os.path.join(\n",
    "    DATA_DIRECTORY, \"wake_sfr_investors202203211516.txt\"\n",
    "))\n",
    "onemap_investors = pd.read_csv(os.path.join(\n",
    "    DATA_DIRECTORY, \"corporate_sfr_properties202205041359.csv\"\n",
    "))\n",
    "nc_investor_transactions = pd.read_csv(os.path.join(\n",
    "    DATA_DIRECTORY,\"nc_sfr_investor_transactions202204251343_prelim.txt\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e975c6",
   "metadata": {},
   "source": [
    "### (1b) Outputting File for Searchable Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e532c186",
   "metadata": {},
   "outputs": [],
   "source": [
    "onemap_investors['site_address'] = onemap_investors['site_address'].fillna('')\n",
    "\n",
    "searchable_residences = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": []\n",
    "}\n",
    "\n",
    "for i, row in onemap_investors.iterrows():\n",
    "    sf_id = row.sf_id\n",
    "    lat = row.lat\n",
    "    lng = row.lng\n",
    "    address = row.site_address\n",
    "    investor = row.investor_label_lvl2\n",
    "    owner = row.owner_clean\n",
    "#     zipcode = str(int(row.site_zip)) if ~np.isnan(float(row.site_zip)) else ''\n",
    "    coordinates = [lng, lat]\n",
    "    \n",
    "    feature = {\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": {\n",
    "            \"type\": \"Point\",\n",
    "            \"coordinates\": coordinates\n",
    "        },\n",
    "        \"properties\": {\n",
    "            \"address\": address,\n",
    "#             \"zip\": zipcode,\n",
    "            \"investorId\": investor + \"-\" + str(i),\n",
    "            \"investor\": investor,\n",
    "            \"owner\": owner\n",
    "        }\n",
    "    }\n",
    "    searchable_residences['features'].append(feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d207b5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "searchable_residences_filename = 'searchable_residences.json'\n",
    "searchable_residences_filepath = os.path.join(DATA_DIRECTORY, searchable_residences_filename)\n",
    "    \n",
    "with open(searchable_residences_filepath, 'w') as f:\n",
    "    json.dump(searchable_residences, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa87520",
   "metadata": {},
   "source": [
    "### (2) Outputting a GeoJSON file for use in Hexbin Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dfe52d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "investor_owned_residences = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": []\n",
    "}\n",
    "\n",
    "for i, row in onemap_investors.iterrows():\n",
    "    sf_id = row.sf_id\n",
    "    lat = row.lat\n",
    "    lng = row.lng\n",
    "    address = \"{0}, {1}, NC {2}\".format(row.site_address, row.site_city, row.site_zip)\n",
    "    investor = row.investor_label_lvl2\n",
    "    coordinates = [lng, lat]\n",
    "    \n",
    "    feature = {\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": {\n",
    "            \"type\": \"Point\",\n",
    "            \"coordinates\": coordinates\n",
    "        },\n",
    "        \"properties\": {\n",
    "            \"id\": sf_id,\n",
    "            \"address\": address,\n",
    "            \"investor\": investor\n",
    "        }\n",
    "    }\n",
    "    investor_owned_residences['features'].append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27a78af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "investor_owned_sfr_filename = 'investor_owned_residences.json'\n",
    "investor_owned_sfr_filepath = os.path.join(DATA_DIRECTORY, investor_owned_sfr_filename)\n",
    "    \n",
    "with open(investor_owned_sfr_filepath, 'w') as f:\n",
    "    json.dump(investor_owned_residences, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b11a5f",
   "metadata": {},
   "source": [
    "**Top 20:** Checking which cities are high on the list of institutionally owned single family residences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b53b29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Raleigh          1581\n",
       "Concord          1295\n",
       "Winston Salem    1169\n",
       "Clayton           991\n",
       "Huntersville      806\n",
       "Greensboro        753\n",
       "Indian Trail      672\n",
       "Monroe            665\n",
       "Mooresville       634\n",
       "Durham            508\n",
       "Gastonia          474\n",
       "High Pt           391\n",
       "Matthews          377\n",
       "Fuquay Varina     364\n",
       "Garner            363\n",
       "Waxhaw            353\n",
       "Kannapolis        309\n",
       "Kernersville      279\n",
       "Wake Forest       266\n",
       "Name: propertycity, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc_investor_transactions.propertycity.value_counts()[1:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a374c5a",
   "metadata": {},
   "source": [
    "### (3a) Output hexagons at a statewide zoom level (hexSideLength = 2 miles) \n",
    "\n",
    "In order to run this step you need to be running `node` and have installed the `npm` packages required by the `hexbin-processing.js` script. You also need to have a local binary of `mapshaper` installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3293611",
   "metadata": {},
   "outputs": [],
   "source": [
    "hexagon_filename = \"hexagonsGeo.json\"\n",
    "hexagon_filepath = os.path.join(DATA_DIRECTORY, hexagon_filename)\n",
    "hexagon_topojson = os.path.join(DATA_DIRECTORY, \"hexagons.json\")\n",
    "# Length of the side of the hexagon in miles\n",
    "hex_side_length = 2\n",
    "\n",
    "subprocess.run([\n",
    "    \"node\",\n",
    "    \"hexbin-processing.js\",\n",
    "    \"--input={0}\".format(investor_owned_sfr_filename),\n",
    "    \"--output={0}\".format(hexagon_filename),\n",
    "    \"--side={0}\".format(hex_side_length)\n",
    "], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "subprocess.run([\n",
    "    MAPSHAPER,\n",
    "    hexagon_filepath,\n",
    "    \"-rename-layers\",\n",
    "    \"names=hexagons\",\n",
    "    \"-o\",\n",
    "    \"format=topojson\",\n",
    "    hexagon_topojson\n",
    "], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c9a98b",
   "metadata": {},
   "source": [
    "### (3b) Output hexagons at a more granular neighborhood zoom level (hexSideLength = 0.2 miles) \n",
    "\n",
    "In order to run this step you need to be running `node` and have installed the `npm` packages required by the `hexbin-processing.js` script. You also need to have a local binary of `mapshaper` installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f811984",
   "metadata": {},
   "outputs": [],
   "source": [
    "zoomed_hexagon_filename = \"zoomedHexagonsGeo.json\"\n",
    "zoomed_hexagon_filepath = os.path.join(DATA_DIRECTORY, zoomed_hexagon_filename)\n",
    "zoomed_hexagon_topojson = os.path.join(DATA_DIRECTORY, \"zoomedHexagons.json\")\n",
    "# Length of the side of the hexagon in miles\n",
    "zoomed_hex_side_length = 0.2\n",
    "\n",
    "subprocess.run([\n",
    "    \"node\",\n",
    "    \"hexbin-processing.js\",\n",
    "    \"--input={0}\".format(investor_owned_sfr_filename),\n",
    "    \"--output={0}\".format(zoomed_hexagon_filename),\n",
    "    \"--side={0}\".format(zoomed_hex_side_length)\n",
    "], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "subprocess.run([\n",
    "    MAPSHAPER,\n",
    "    zoomed_hexagon_filepath,\n",
    "    \"-rename-layers\",\n",
    "    \"names=hexagons\",\n",
    "    \"-o\",\n",
    "    \"format=topojson\",\n",
    "    zoomed_hexagon_topojson\n",
    "], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374ef718",
   "metadata": {},
   "source": [
    "# (B) Neighborhood Map: Join Investor Data w/ Residential Building Outlines\n",
    "\n",
    "Here I'm taking OpenStreetMaps data, and combining it with both North Carolina parcel data and institutionally owned single-family resdience data. The end result is a topojson that has joined individual building outlines with the institution that owns it. There's a better way to do this I'm sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e4345fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import shape, GeometryCollection, Polygon, MultiPolygon\n",
    "\n",
    "# Overpass API isntance\n",
    "OVERPASS_API = overpass.API()\n",
    "\n",
    "# North Mecklenburg County bounding box\n",
    "# Overpass API accepts [lat1, lng1, lat2, lng2] ordering\n",
    "bbox = [35.28360260045482, -80.90555191040039, 35.304041146172075, -80.85420370101929]\n",
    "bbox_string = ', '.join([str(num) for num in bbox])\n",
    "\n",
    "# Need to switch and reorder the lat/lng\n",
    "# Mapshaper API accepts [lngMin, latMin, lngMax, latMax]\n",
    "bbox_xy = [min(bbox[1], bbox[3]), min(bbox[0], bbox[2]), max(bbox[1], bbox[3]), max(bbox[0], bbox[2])]\n",
    "bbox_xy_string = ', '.join([str(num) for num in bbox_xy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82ab953",
   "metadata": {},
   "source": [
    "### (1) Get underlying geometries from Overpass API\n",
    "\n",
    "Output TopoJSON files since those are relatively compressed for mapping purposes. This is not really about joining any data. However, these steps are necessary for mapping purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d347ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import topojson as tp\n",
    "\n",
    "def output_topojson(geojson, layer_name, property_fields=[]):\n",
    "    topojson = tp.Topology(geojson, object_name=layer_name)\n",
    "    topojson_output = json.loads(topojson.to_json())\n",
    "    \n",
    "    if len(property_fields) > 0:\n",
    "        topojson_output = topojson.output\n",
    "        geometries = topojson_output['objects'][layer_name]['geometries']\n",
    "        \n",
    "        for i, geom in enumerate(geometries):\n",
    "            properties = geojson['features'][i]['properties']\n",
    "            properties_to_keep = { field: properties[field] for field in property_fields }\n",
    "            topojson_output['objects'][layer_name]['geometries'][i]['properties'] = properties_to_keep\n",
    "    \n",
    "    output_filepath = os.path.join(DATA_DIRECTORY, '{0}.json'.format(layer_name))\n",
    "\n",
    "    with open(output_filepath, 'w') as f:\n",
    "        json.dump(topojson_output, f)\n",
    "\n",
    "overpass_highways = OVERPASS_API.get(\"\"\"\n",
    "( way[\"highway\"=\"motorway\"]({0});\n",
    "  way[\"highway\"=\"trunk\"]({0});\n",
    "  way[\"highway\"=\"primary\"]({0});\n",
    "  way[\"highway\"=\"secondary\"]({0});\n",
    "  way[\"highway\"=\"tertiary\"]({0});\n",
    ")\n",
    "\"\"\".format(bbox_string), verbosity='geom')\n",
    "\n",
    "overpass_streets = OVERPASS_API.get(\"\"\"\n",
    "(\n",
    "  way[\"highway\"=\"service\"]({0});\n",
    "  way[\"highway\"=\"residential\"]({0});\n",
    ")\n",
    "\"\"\".format(bbox_string), verbosity='geom')\n",
    "\n",
    "overpass_turning_circles = OVERPASS_API.get(\"\"\"\n",
    "(\n",
    "  node[\"highway\"=\"turning_circle\"]({0});\n",
    ")\n",
    "\"\"\".format(bbox_string), verbosity='geom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "668a207d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/topojson/core/extract.py:403: ShapelyDeprecationWarning: __len__ for multi-part geometries is deprecated and will be removed in Shapely 2.0. Check the length of the `geoms` property instead to get the  number of parts of a multi-part geometry.\n",
      "  self.records_collection = len(geom)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/topojson/core/extract.py:409: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for idx, geo in enumerate(geom):\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/topojson/core/extract.py:182: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  self._extract_point(geom)\n",
      "<__array_function__ internals>:180: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/shapely/geometry/base.py:250: ShapelyDeprecationWarning: Setting the 'coords' to mutate a Geometry in place is deprecated, and will not be possible any more in Shapely 2.0\n",
      "  super().__setattr__(name, value)\n"
     ]
    }
   ],
   "source": [
    "output_topojson(overpass_turning_circles, 'turning_circles')\n",
    "output_topojson(overpass_streets, 'streets', ['highway'])\n",
    "output_topojson(overpass_highways, 'highways', ['highway'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff8024e",
   "metadata": {},
   "source": [
    "### (2) Get residential buildings from Overpass API\n",
    "API returns a FeatureCollection, a GeoJSON type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40edadf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "overpass_residential = OVERPASS_API.get(\"\"\"\n",
    "((way[\"building\"]({0}); relation[\"building\"]({0});););      \n",
    "\"\"\".format(bbox_string), verbosity='geom')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddeb5b6",
   "metadata": {},
   "source": [
    "### (3) Convert LineStrings to Polygons (assumes closed LineStrings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8223758",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapely_features = []\n",
    "for feature in overpass_residential.features:\n",
    "    if feature.geometry.type == \"MultiPolygon\":\n",
    "        polygons = [Polygon(p) for p in feature[\"geometry\"][\"coordinates\"][0]]\n",
    "        shapely_features.append(shape(MultiPolygon(polygons)).buffer(0))\n",
    "    else:\n",
    "        shapely_features.append(shape(Polygon(feature[\"geometry\"][\"coordinates\"])).buffer(0))\n",
    "    \n",
    "shapely_residential = GeometryCollection(shapely_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fe2f1c",
   "metadata": {},
   "source": [
    "### (4) Get the neighborhood outline shape\n",
    "Manually draw neighborhood outline on https://geojson.io/\n",
    "\n",
    "Download a geoJSON file named `outline_neighborhood.geojson`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27b859e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_filepath = os.path.join(DATA_DIRECTORY, 'outline_neighborhood.geojson')\n",
    "with open(neighborhood_filepath) as f:\n",
    "    features = json.load(f)[\"features\"]\n",
    "\n",
    "# NOTE: buffer(0) is a trick for fixing scenarios where polygons have overlapping coordinates \n",
    "outline = GeometryCollection([shape(feature[\"geometry\"]).buffer(0) for feature in features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af954430",
   "metadata": {},
   "source": [
    "### (5) Find all residential buildings contained in the neighborhood outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e86c80d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_buildings = []\n",
    "for bldg in shapely_residential.geoms:\n",
    "    # add intersection to the list\n",
    "    if outline.contains(bldg):\n",
    "        neighborhood_buildings.append(bldg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5968e609",
   "metadata": {},
   "source": [
    "### (6) Get tax parcels that interesect with neighborhood outline\n",
    "\n",
    "Time consuming step. I could probably improve this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11a8984",
   "metadata": {},
   "outputs": [],
   "source": [
    "parcel_taxdata_filepath = os.path.join(DATA_DIRECTORY, 'parcel_taxdata', 'Parcel_TaxData.shp')\n",
    "parcel_projected_filepath = os.path.join(DATA_DIRECTORY, 'parcel_projected.json')\n",
    "\n",
    "subprocess.run([\n",
    "    MAPSHAPER,\n",
    "    parcel_taxdata_filepath,\n",
    "    \"-proj\",\n",
    "    \"wgs84\",\n",
    "    \"-o\",\n",
    "    \"format=geojson\",\n",
    "    parcel_projected_filepath\n",
    "], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9c3f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_parcel_filepath = os.path.join(DATA_DIRECTORY, 'parcel_neighborhood.json')\n",
    "\n",
    "subprocess.run([\n",
    "    MAPSHAPER,\n",
    "    parcel_projected_filepath,\n",
    "    \"-clip\",\n",
    "    \"bbox={0}\".format(bbox_xy_string),\n",
    "    \"-o\",\n",
    "    \"format=geojson\",\n",
    "    neighborhood_parcel_filepath\n",
    "], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee1488a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(neighborhood_parcel_filepath) as f:\n",
    "    features = json.load(f)[\"features\"]\n",
    "\n",
    "neighborhood_parcels = GeometryCollection([shape(feature['geometry']).buffer(0) for feature in features])\n",
    "neighborhood_properties = [feature['properties'] for feature in features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31835b6a",
   "metadata": {},
   "source": [
    "### (6) Get tax parcels that interesect with residential buildings\n",
    "\n",
    "Checking if a tax parcel contains the residential building centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ddc67ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_building_properties = []\n",
    "\n",
    "for bldg in neighborhood_buildings:\n",
    "    centroid = bldg.centroid\n",
    "    for i, parcel in enumerate(neighborhood_parcels.geoms):\n",
    "        if parcel.contains(centroid):\n",
    "            neighborhood_building_properties.append(neighborhood_properties[i])\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f93c624",
   "metadata": {},
   "source": [
    "### (7) Join investor ownership data with residential building feature\n",
    "\n",
    "Uses parcel ID as the unique identifier and only keep the investor property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e32a6158",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_properties = []\n",
    "for i, properties in enumerate(neighborhood_building_properties):\n",
    "    # parcel id\n",
    "    pid = properties['pid']\n",
    "    sfr_match = onemap_investors[onemap_investors.parcel_identification1 == pid]\n",
    "    investor = \"\"\n",
    "    if len(sfr_match) > 1:\n",
    "        investor = list(sfr_match['investor_label_lvl2'])[0]\n",
    "    elif len(sfr_match) > 0:\n",
    "        investor = sfr_match['investor_label_lvl2'].item()\n",
    "    final_properties.append({\"investor\": investor})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7637cf9e",
   "metadata": {},
   "source": [
    "### (8) Convert Shapely geometries to geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f98ab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely.wkt\n",
    "homes = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": []\n",
    "}\n",
    "\n",
    "for i, bldg in enumerate(neighborhood_buildings):\n",
    "    feature = geojson.Feature(geometry=shapely.wkt.loads(bldg.wkt), properties=final_properties[i])\n",
    "    homes['features'].append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f0619d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_topojson(homes, 'homes', ['investor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d68392",
   "metadata": {},
   "source": [
    "# (C) Timeline Map: Formatting NC Statewide Transaction Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3f8830",
   "metadata": {},
   "source": [
    "### (1) Format NC investor transaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37ccd961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "nc_investor_transactions = nc_investor_transactions.fillna(\"\") \n",
    "nc_investor_transactions['year'] = nc_investor_transactions.saledate.str.split('-').str[0].astype(int)\n",
    "nc_investor_transactions['month'] = nc_investor_transactions.saledate.str.split('-').str[1].astype(int)\n",
    "nc_investor_transactions['day'] = nc_investor_transactions.saledate.str.split('-').str[2].astype(int)\n",
    "nc_investor_transactions['saledate_ordered'] = nc_investor_transactions.saledate.str.replace('-','').astype(int)\n",
    "nc_investor_transactions = nc_investor_transactions.sort_values(['saledate_ordered']).reset_index(drop=True)\n",
    "nc_investor_transactions['lng_rounded'] = round(nc_investor_transactions.lng,2)\n",
    "nc_investor_transactions['lat_rounded'] = round(nc_investor_transactions.lat,2)\n",
    "nc_investor_transactions['timestamp'] = [datetime(row.year, row.month, row.day).replace(tzinfo=timezone.utc).timestamp() for i, row in nc_investor_transactions.iterrows()]\n",
    "nc_investor_transactions['timestamp'] = nc_investor_transactions['timestamp'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc98bad",
   "metadata": {},
   "source": [
    "### (2) Output timeline geojson data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e73609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline_geodata = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": []\n",
    "}\n",
    "\n",
    "def to_str_int(string):\n",
    "    if not string:\n",
    "        return ''\n",
    "    return str(int(string))\n",
    "\n",
    "for i, row in nc_investor_transactions.iterrows():\n",
    "    transid = row.transid\n",
    "    saledate_ordered = row.saledate_ordered\n",
    "    year = row.year\n",
    "    month = row.month\n",
    "    day = row.day\n",
    "    timestamp = datetime(year, month, day).replace(tzinfo=timezone.utc).timestamp()\n",
    "    lat = row.lat_rounded\n",
    "    lng = row.lng_rounded\n",
    "    address = \"{0}, {1}, {2} {3}\".format(\n",
    "        row.propertyfullstreetaddress,\n",
    "        row.propertycity,\n",
    "        row.propertystate,\n",
    "        to_str_int(row.propertyzip)\n",
    "    )\n",
    "    investor = row.investor_label_lvl2\n",
    "    coordinates = [lng, lat]\n",
    "    \n",
    "    feature = {\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": {\n",
    "            \"type\": \"Point\",\n",
    "            \"coordinates\": coordinates\n",
    "        },\n",
    "        \"properties\": {\n",
    "            \"timestamp\": timestamp,\n",
    "        }\n",
    "    }\n",
    "    timeline_geodata['features'].append(feature)\n",
    "    \n",
    "timeline_geojson_filepath = os.path.join(DATA_DIRECTORY, 'timeline_geojson.json')\n",
    "\n",
    "with open(timeline_geojson_filepath, 'w') as f:\n",
    "    json.dump(timeline_geodata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cd2880",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline_filepath = os.path.join(DATA_DIRECTORY, 'timeline.json')\n",
    "\n",
    "subprocess.run([\n",
    "    MAPSHAPER,\n",
    "    timeline_geojson_filepath,\n",
    "    \"-rename-layers\",\n",
    "    \"names=timeline\",\n",
    "    \"-o\",\n",
    "    \"format=topojson\",\n",
    "    timeline_filepath\n",
    "], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b2c609",
   "metadata": {},
   "source": [
    "### (3) Output cumulative transaction data by day of transaction\n",
    "\n",
    "Important to get the first and last timestamps for the scrolling map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14ba1792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "timestamp_year_count = {}\n",
    "timestamp_year_cumulative = {}\n",
    "for timestamp in sorted(nc_investor_transactions.timestamp.unique()):\n",
    "    timestamp_year_count[str(timestamp)] = {}\n",
    "\n",
    "cumulative_count = {\"pre-2010\": {\"current\": 0, \"previous\": 0, \"total\": 0}}\n",
    "per_year_count = {\"pre-2010\": 0}\n",
    "for year in sorted(nc_investor_transactions.year.unique()):\n",
    "    if year < 2010:\n",
    "        continue\n",
    "    per_year_count[str(year)] = 0\n",
    "    cumulative_count[str(year)] = {\"current\": 0, \"previous\": 0, \"total\": 0}\n",
    "\n",
    "cumulative_total = 0\n",
    "for i, row in nc_investor_transactions.iterrows():\n",
    "    year = row.year\n",
    "    if year < 2010:\n",
    "        year = \"pre-2010\"\n",
    "        \n",
    "    if cumulative_count[str(year)][\"current\"] == 0 and year != \"pre-2010\":\n",
    "        if year == 2010:\n",
    "            prev_year = \"pre-2010\"\n",
    "        else:\n",
    "            prev_year = year - 1\n",
    "        cumulative_count[str(year)][\"previous\"] = cumulative_total\n",
    "    \n",
    "    \n",
    "    timestamp = row.timestamp\n",
    "    per_year_count[str(year)] += 1\n",
    "    cumulative_count[str(year)][\"current\"] += 1\n",
    "    cumulative_count[str(year)][\"total\"] = cumulative_count[str(year)][\"current\"] + cumulative_count[str(year)][\"previous\"]\n",
    "    \n",
    "    copy_per_year_count = copy.deepcopy(per_year_count)\n",
    "    copy_cumulative_count = copy.deepcopy(cumulative_count)\n",
    "    \n",
    "    timestamp_year_count[str(timestamp)] = copy_per_year_count\n",
    "    timestamp_year_cumulative[str(timestamp)] = copy_cumulative_count\n",
    "    cumulative_total += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84ad8b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First: 1339113600, Last: 1615939200\n"
     ]
    }
   ],
   "source": [
    "timestamp_keys = sorted(list(timestamp_year_count.keys()))\n",
    "print(\"First: {0}, Last: {1}\".format(timestamp_keys[0], timestamp_keys[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11c50a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filepath = os.path.join(DATA_DIRECTORY, 'timestamps_cumulative.json')\n",
    "    \n",
    "with open(output_filepath, 'w') as f:\n",
    "    json.dump(timestamp_year_cumulative, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33ff008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filepath = os.path.join(DATA_DIRECTORY, 'timestamps_aggregate.json')\n",
    "    \n",
    "with open(output_filepath, 'w') as f:\n",
    "    json.dump(timestamp_year_count, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
